{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IJvl-EEESCA"
      },
      "source": [
        "# <font color=red>LangChain:  Quickstart Guide</font>\n",
        "- https://docs.langchain.com/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Virtual Enironments\n",
        "There were a couple of requests for a few refresher comments on virtual environments (venvs), so I added this section.\n",
        "\n",
        "There are multiple ways to create a virtual environment for python work.</br>\n",
        "The two that I have used are:  anaconda and python itself.</br>\n",
        "Here, we will use the python method to show how I setup things for the LangChain examples.\n",
        "\n",
        "The following lines can be entered at your shell prompt without the $.</br>\n",
        "None of them will damage anything, but you should still read through them to make sure you get the idea before starting.\n",
        "\n",
        "<pre>\n",
        "$ mkdir ~/VENVS  # create a directory to hold your virtual envs; not nec but useful\n",
        "\n",
        "$ which python3   # see where your current python3 is located\n",
        "\n",
        "$ python3 -m venv ~/VENVS/LCVENV   # create venv for LangChain work\n",
        "$ source ~/VENVS/LCVENV/bin/activate   # this activates the venv AND causes your prompt to begin with (LCVENV)\n",
        "\n",
        "$ which python3   # and now your python3 should be the one in the venv\n",
        "\n",
        "$ python3 -m pip install langchain openai .... # install packages you want in the new venv; or do this later\n",
        "\n",
        "$ python3 some_program_that_uses_langchain   # prove you use the installed packages\n",
        "\n",
        "$ deactivate    # deactivate the venv AND your prompt loses the (LCVENV) on the front\n",
        "\n",
        "$ which python3   # you revert to the python3 prior to activating the venv\n",
        "</pre>\n",
        "\n",
        "An important thing to know is that you can activate a venv in VSCode so that it will be used when you run cells.</br>\n",
        "You should be able to activate a venv where you would normally \"Select Kernel\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Install langchain and openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain openai  # OR, you could run the pip cmd in your shell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Put OpenAI key into your environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# do this in your shell:\n",
        "#      export OPENAI_API_KEY=\"your_key\"\n",
        "import os \n",
        "print( os.getenv(\"OPENAI_API_KEY\") )   # this will print your key\n",
        "\n",
        "# OR you can directly place it into openai\n",
        "#   but it will be readable in your code, which is not a good idea\n",
        "import openai\n",
        "openai.api_key = \"your_key\"   # key appears in clear text here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### First, let's verify that we can use LangChain with an OpenAI LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ0GlWotE_S0"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI   # a simple completion model\n",
        "\n",
        "llm = OpenAI()\n",
        "query = \"Tell me a Dad joke about dogs.\"\n",
        "response = llm(query)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What are chains?\n",
        "A chain is a multi-step workflow, composed of links.<br/><br/>\n",
        "A link is one of:\n",
        "- a prompt\n",
        "- an LLM\n",
        "- another chain\n",
        "#### Let's do just one small chain consisting of a prompt and a chat LLM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains  import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI   # a chat model\n",
        "\n",
        "# note prompt's similarity to python f-strings\n",
        "template = \"Tell me a {joke_type} joke about {topic}.\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# here we are only printing the prompt, not using it with an LLM\n",
        "# we just want to show that we can make substitutions for the input_variables\n",
        "print(prompt.format(joke_type=\"dad\",topic=\"dogs\"))\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7, max_tokens=128)\n",
        "\n",
        "# now, let's create a chain consisting of the prompt and the LLM\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "response = llm_chain.run(joke_type=\"dad\",topic=\"my cat named Gizmo\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMZi6NDm9npKydMJRyJPAT2",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
